{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#1. What are the three stages to build the hypotheses or model in machine learning?\n",
    "\n",
    "1 - You must select appropriate data from your population that will give you the best sample for the problem.\n",
    "2 - You must preprocess the data in terms of formatting and cleaning the data.  Then obtaining an appropriate sample.\n",
    "3 - You must transform your data in terms of scaling/normalizing the data so that different units of measurement or larger/smaller types of data do not offset the results.  Finally you may need to decompose a single measurement into more useful pieces, or aggregate multiple measurements into a more helpful single measurement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. What is the standard approach to supervised learning?\n",
    "\n",
    "Run an algorithm on data that has inputs (x) and outputs (y).  The algorithm learns which combinations of inputs lead to a desired output.  The learning portion takes place with the learning set.  Once the algorithm has learned an optimal amount, the algorithm is run on the test set, to see how it performs in practical application.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. What is Training set and Test set?\n",
    "\n",
    "The training set is a portion of your entire data set, usually larger than your testing set, that is used to train and refine your algorithm.  Once the algorithm has learned to predict the correct outcome sufficiently, you then run the trained algorithm on the test set.  As this is novel data to the algorithm, it is a better example of 'real-world' applicability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#4. What is the general principle of an ensemble method and what is bagging and\n",
    "boosting in ensemble method?\n",
    "\n",
    "Ensemble methods will use multiple learners in order to achieve greater accuracy.  Homogeneous methods will use several of the same types of learners, while heterogenous methods will use different types of learners.\n",
    "\n",
    "Bagging is short for bootstrap aggregation. The same algorithm is used on multiple subsets of the training data, with the subset data not removed (or reintroduced into the training data) after each trial of the model.  This provides multiple trainings with slightly varied data sets.\n",
    "\n",
    "Boosting similarly trains on the same training dataset multiple times, but subsequent data selection is different.  After each training, the next dataset is comprised of the incorrect predictions from the prior training with some random data from the training set.  This can loop many times, each time the incorrect answers being selected for the next training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. How can you avoid overfitting?\n",
    "\n",
    "Numerous methods exist to reduce overfitting. One simple way is to only train your algorithm on your training dataset a smaller number of times.  Running your algorithm too many times tends to train the algorithm that the random data or artifacts are significant, and it throws off the algorithm.  Also you can a k-fold holdout, which breaks your training set into several groups that are each interatively analyzed by the algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
